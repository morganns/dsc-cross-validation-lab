{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Perform cross validation on a model\n",
    "- Compare and contrast model validation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started\n",
    "\n",
    "We included the code to pre-process the Ames Housing dataset below. This is done for the sake of expediency, although it may result in data leakage and therefore overly optimistic model metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n",
    "\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Perform a train-test split with a test set of 20% and a random state of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (assign 20% to test set)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model\n",
    "\n",
    "Fit a linear regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a linear regression model\n",
    "# Initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "lin_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE\n",
    "\n",
    "Calculate the mean squared error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error from sklearn.metrics\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Mean Squared Error: 0.1523399721070817\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE on test set\n",
    "# Generate predictions on the test set\n",
    "y_test_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Display the MSE result\n",
    "print(\"Test Set Mean Squared Error:\", mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn\n",
    "\n",
    "Now let's compare that single test MSE to a cross-validated test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from sklearn.model_selection\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find MSE scores for a 5-fold cross-validation\n",
    "mse_scores = -cross_val_score(lin_reg, X, y, cv=5, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE Scores: [0.12431546 0.19350065 0.1891053  0.17079325 0.20742705]\n",
      "Average Cross-Validation MSE: 0.1770283421000112\n"
     ]
    }
   ],
   "source": [
    "# Get the average MSE score\n",
    "avg_mse = mse_scores.mean()\n",
    "\n",
    "# Display the MSE scores and the average MSE\n",
    "print(\"Cross-Validation MSE Scores:\", mse_scores)\n",
    "print(\"Average Cross-Validation MSE:\", avg_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and contrast the results. What is the difference between the train-test split and cross-validation results? Do you \"trust\" one more than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "\n",
    " # 🏠 Comparing Train-Test Split vs. Cross-Validation Results\n",
    "\n",
    "Now that we've calculated both:  \n",
    "✅ **Train-test split MSE** (single test set evaluation).  \n",
    "✅ **Cross-validation MSE** (average of 5 different test set evaluations).  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Key Differences\n",
    "\n",
    "### **Train-Test Split**  \n",
    "- Evaluates the model on **one** test set.  \n",
    "- **Strengths:**  \n",
    "  - Fast and simple.  \n",
    "  - Mimics real-world scenarios where models are trained and tested separately.  \n",
    "- **Weaknesses:**  \n",
    "  - The results depend on how the data is split.  \n",
    "  - Can be unstable if the split is **lucky or unlucky** (leading to misleading results).  \n",
    "\n",
    "### **Cross-Validation (5-fold)**  \n",
    "- Evaluates the model on **5 different test sets** and **averages the results**.  \n",
    "- **Strengths:**  \n",
    "  - More reliable and stable evaluation.  \n",
    "  - Uses more data for training, improving model performance.  \n",
    "  - Reduces bias from lucky or unlucky splits.  \n",
    "- **Weaknesses:**  \n",
    "  - Computationally expensive (takes longer to run).  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 Do We Trust One More?\n",
    "Yes! **Cross-validation is more trustworthy** 🚀  \n",
    "\n",
    "- **Why?** It reduces the impact of **random luck** in train-test splits.  \n",
    "- Instead of relying on **one test set**, cross-validation **averages over multiple test sets** for a more **stable** and **reliable** error estimate.  \n",
    "- If the **train-test split MSE is very different from the cross-validation MSE**, the train-test split might be misleading.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 When to Use Each Method?\n",
    "- **Use Train-Test Split** when you need a quick evaluation or when computational efficiency is a concern.  \n",
    "- **Use Cross-Validation** when you want a more reliable evaluation before making final decisions, especially in small datasets.  \n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **Final Thought:**  \n",
    "If the train-test MSE and cross-validation MSE are similar, the model is likely stable.  \n",
    "If they are **very different**, it means the train-test split was either **lucky or unlucky**, so cross-validation is the better choice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Let's Build It from Scratch!\n",
    "\n",
    "### Create a Cross-Validation Function\n",
    "\n",
    "Write a function `kfolds(data, k)` that splits a dataset into `k` evenly sized pieces. If the full dataset is not divisible by `k`, make the first few folds one larger then later ones.\n",
    "\n",
    "For example, if you had this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>indigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>violet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color\n",
       "0     red\n",
       "1  orange\n",
       "2  yellow\n",
       "3   green\n",
       "4    blue\n",
       "5  indigo\n",
       "6  violet"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data = pd.DataFrame({\n",
    "    \"color\": [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\n",
    "})\n",
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kfolds(example_data, 3)` should return:\n",
    "\n",
    "* a dataframe with `red`, `orange`, `yellow`\n",
    "* a dataframe with `green`, `blue`\n",
    "* a dataframe with `indigo`, `violet`\n",
    "\n",
    "Because the example dataframe has 7 records, which is not evenly divisible by 3, so the \"leftover\" 1 record extends the length of the first dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    folds = []\n",
    "    \n",
    "    # Calculate the base size of each fold\n",
    "    fold_size = len(data) // k\n",
    "    remainder = len(data) % k  # Extra records to distribute among first few folds\n",
    "\n",
    "    start_idx = 0\n",
    "    for i in range(k):\n",
    "        # First 'remainder' folds get an extra record\n",
    "        extra = 1 if i < remainder else 0\n",
    "        end_idx = start_idx + fold_size + extra\n",
    "        folds.append(data.iloc[start_idx:end_idx])  # Append the slice to folds\n",
    "        start_idx = end_idx  # Update start index for the next fold\n",
    "\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    color\n",
      "0     red\n",
      "1  orange\n",
      "2  yellow \n",
      "\n",
      "   color\n",
      "3  green\n",
      "4   blue \n",
      "\n",
      "    color\n",
      "5  indigo\n",
      "6  violet \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = kfolds(example_data, 3)\n",
    "for result in results:\n",
    "    print(result, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Your Function to the Ames Housing Data\n",
    "\n",
    "Get folds for both `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Folds Sizes: [292, 292, 292, 292, 292]\n",
      "Y Folds Sizes: [292, 292, 292, 292, 292]\n"
     ]
    }
   ],
   "source": [
    "# Apply kfolds() to ames_data with 5 folds\n",
    "# Apply kfolds() to the Ames Housing dataset with 5 folds\n",
    "\n",
    "# Get folds for features (X) and target variable (y)\n",
    "X_folds = kfolds(X, 5)\n",
    "y_folds = kfolds(y, 5)\n",
    "\n",
    "# Display the number of records in each fold\n",
    "print(\"X Folds Sizes:\", [len(fold) for fold in X_folds])\n",
    "print(\"Y Folds Sizes:\", [len(fold) for fold in y_folds])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Linear Regression for Each Fold and Calculate the Test Error\n",
    "\n",
    "Remember that for each fold you will need to concatenate all but one of the folds to represent the training data, while the one remaining fold represents the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1243154614843743, 0.19350064631313127, 0.18910530431311184, 0.17079325250026917, 0.2074270458891695]\n"
     ]
    }
   ],
   "source": [
    "# Replace None with appropriate code\n",
    "test_errs = []\n",
    "k = 5\n",
    "\n",
    "for n in range(k):\n",
    "    # Split into train and test for the fold\n",
    "    X_train = pd.concat([X_folds[i] for i in range(k) if i != n])  # Combine all but the nth fold\n",
    "    X_test = X_folds[n]  # The nth fold is the test set\n",
    "    y_train = pd.concat([y_folds[i] for i in range(k) if i != n])  # Combine all but the nth fold\n",
    "    y_test = y_folds[n]  # The nth fold is the test set\n",
    "    \n",
    "    # Fit a linear regression model\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    # Evaluate test errors\n",
    "    y_pred = lin_reg.predict(X_test)\n",
    "    test_errs.append(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(test_errs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code was written correctly, these should be the same errors as scikit-learn produced with `cross_val_score` (within rounding error). Test this out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual K-Fold Test Errors: [0.1243154614843743, 0.19350064631313127, 0.18910530431311184, 0.17079325250026917, 0.2074270458891695]\n",
      "Scikit-Learn Cross-Validation Test Errors: [0.12431546 0.19350065 0.1891053  0.17079325 0.20742705]\n",
      "Difference between Manual and Scikit-Learn MSEs: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Compare your results with sklearn results\n",
    "# Perform 5-fold cross-validation using scikit-learn's cross_val_score\n",
    "sklearn_mse_scores = -cross_val_score(lin_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Compare results\n",
    "print(\"Manual K-Fold Test Errors:\", test_errs)\n",
    "print(\"Scikit-Learn Cross-Validation Test Errors:\", sklearn_mse_scores)\n",
    "\n",
    "# Check if the results are similar within a small rounding difference\n",
    "difference = np.abs(np.array(test_errs) - sklearn_mse_scores)\n",
    "print(\"Difference between Manual and Scikit-Learn MSEs:\", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Hopefully you have a clearer understanding of the underlying logic for cross-validation if you attempted this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are more robust than train-test split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
